{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NO9AQlONvNWs",
        "outputId": "2201da93-347f-4a5b-f6cf-e7123cc610df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Using cached openai-1.77.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from openai) (0.28.1)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Using cached jiter-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from openai) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from openai) (1.3.1)\n",
            "Collecting tqdm>4 (from openai)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Using cached openai-1.77.0-py3-none-any.whl (662 kB)\n",
            "Using cached jiter-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: tqdm, jiter, openai\n",
            "Successfully installed jiter-0.9.0 openai-1.77.0 tqdm-4.67.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1746536582307
        },
        "id": "rnsFHba_vSnf"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1746536583485
        },
        "id": "zc--KuHRvieu"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = '...'\n",
        "\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gather": {
          "logged": 1746536992270
        },
        "id": "bq3ZhwTMPmyO",
        "outputId": "8f7ada0d-d398-4313-916e-d8f1a40073a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1, got 10 results.\n",
            "Processed batch 2, got 10 results.\n",
            "Processed batch 3, got 10 results.\n",
            "Processed batch 4, got 10 results.\n",
            "Batch 5: no JSON array found\n",
            "[{\"review_id\": \"q2zPKtW-thQuAXUiTU4Uqw\", \"review_snippet\": \"I'm always on the hunt for a tasty dairy-free latte and theirs (almond/coconut milk blend) is definitely one of the best in Nashville! Will definitely be back.\", \"sentiment\": \"Positive\", \"score\": 8}, {\"review_id\": \"Tb07UEPbKhNmKf7Py_popA\", \"review_snippet\": \"Let me start off by saying we are Not big drinkers so a night out for us consist of two  to three drinks and we start to feel a good buzz. So it's our first time to Nashville we head straight to Broadway on Saturday night. Want to get a good buzz going and enjoy the atmosphere and town. . The place is beautiful, very modern. Sat in the second level bar had the Buckshot and 2 jack and cokes to follow.  All I have to say is SUPER weak drinks!! Paid about $75 and felt Like we drank water!!!\", \"sentiment\": \"Negative\", \"score\": 2}, {\"review_id\": \"_OZPWJU5yYkuaXj8wV_fAw\", \"review_snippet\": \"100% Best Deli/Hoagie Spot in the Main Line! This place is special. You want a hoagie you will never forget? This is the place. Expect a wait during lunch because this neighborhood deli has a reputation for being a delicious and affordable place to go. It's a family business in a family town and I'm always treated like family when I go there. If you haven't been here, you really are missing out!\", \"sentiment\": \"Positive\", \"score\": 9}, {\"review_id\": \"hu_mry0oMMKrPUU2Ycw1Mw\", \"review_snippet\": \"Headed here Saturday night with friends for food and drinks...only they aren't serving food, yet at least...the ambiance is nice, it reminded me of a more European feel (no bar stools). The Bartender was very friendly and called us \\\"friend\\\" they did serve us a small shepards pie as a snack..my friend from England was not impressed, said his mother made it better but I have never had it and thought it was pretty tasty. I think i will let them get a bit more established and try it again.\", \"sentiment\": \"Neutral\", \"score\": 5}, {\"review_id\": \"ekmKB9kOOJhjnwf6SipAlQ\", \"review_snippet\": \"This place is great!  Clean and tidy, which is more than I can say for a lot of Chinese places. They've definitely done some upgrading. Salad bar was completely stocked and very clean. Because it...\n",
            "Processed batch 6, got 10 results.\n",
            "Processed batch 7, got 10 results.\n",
            "Batch 8: JSON parse failed after cleaning: Invalid control character at: line 34 column 938 (char 4416)\n",
            "Processed batch 9, got 10 results.\n",
            "Processed batch 10, got 10 results.\n",
            "Processed batch 11, got 10 results.\n",
            "Batch 12: no JSON array found\n",
            "[{\"review_id\": \"4vRfkS_5gd3R3bhyahswew\", \"review_snippet\": \"I was more than a little hesitant to try Teavana after reading reviews of pushy salespeople. But praise be to Yelp- they must've learned their lesson because I was here two days in a row with two completely different staff and while there was a lot of explaining/demoing there was no pressure. In fact today a wonderful salesperson dissuaded me from buying the overly expensive starter kit and rather get me a tea I liked,  a tin, & tumbler on sale! (Please note this starter setup was HALF the cost of the actual kit)\\n\\nI was thoroughly impressed with the staff who were able to guess exactly which tea I wanted after I blankly starred at them and said \\\"I dunno I think it's green tea based with fruit...\\\" Even more impressive was the reassurance that you will know if you will like the tea simply by smell, I didn't believe it but totally true.\\n\\nCool note: Teavana was purchased by Starbucks last year so those Starbucks gift cards work here and if you have a registered card you can accrue stars here as well!\",\"sentiment\": \"Positive\",\"score\": 9},{\"review_id\": \"qP0lkVGZknW1Xy8Hak5ZRw\", \"review_snippet\": \"I love getting salads here!  They're reasonably priced, yummy and are a convenient carry out.  The salads are fresher and cheaper than most other places in the category (I'm looking at you, Bread Co).\\n\\nI have always had speedy and friendly service here, whether I dine in or carry out.  They sometimes host local author talks and book signings, which I really think is an awesome way to build a community feeling.\\n\\n\\nI HIGHLY recommend 6 North Cafe or a quick lunch, a place to grab a bite while working or studying or a for carry out.  Essentially, try this place!\",\"sentiment\": \"Positive\",\"score\": 8},{\"review_id\": \"_yLw_SVB4EkNlKFLyCNTxA\", \"review_snippet\": \"Lots of potential here, but a lack of preparation for the insane crowds that came out meant...\n",
            "Processed batch 13, got 10 results.\n",
            "Processed batch 14, got 10 results.\n",
            "Processed batch 15, got 10 results.\n",
            "Batch 16: JSON parse failed after cleaning: Invalid control character at: line 22 column 1217 (char 2286)\n",
            "Processed batch 17, got 10 results.\n",
            "Processed batch 18, got 10 results.\n",
            "Processed batch 19, got 10 results.\n",
            "Processed batch 20, got 3 results.\n",
            "Sentiment analysis complete. Total items: 153. Results saved to sentiment_results.csv.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import csv\n",
        "import re\n",
        "from openai import OpenAI\n",
        "\n",
        "# Batch settings\n",
        "BATCH_SIZE = 10\n",
        "\n",
        "# System prompt for batched sentiment analysis\n",
        "system_instruction = \"\"\"\n",
        "You are an expert sentiment analyst. You will be given a JSON array of review objects.\n",
        "Each object has:\n",
        "  - review_id: a unique identifier for the review\n",
        "  - review_snippet: the full text of the review\n",
        "For each object, return a new object with keys:\n",
        "  - review_id: same identifier\n",
        "  - review_snippet: the original snippet (full text)\n",
        "  - sentiment: one of \"Positive\", \"Neutral\", or \"Negative\"\n",
        "  - score: an integer from 0 to 10 representing how positive it is\n",
        "Return only a JSON array of these objects, without any additional text.\n",
        "\"\"\"\n",
        "\n",
        "# Helper to split list into batches\n",
        "def chunk(lst, size):\n",
        "    for i in range(0, len(lst), size):\n",
        "        yield lst[i:i + size]\n",
        "\n",
        "# Load dataset\n",
        "with open(\"sample_200_review.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    reviews = json.load(f)\n",
        "\n",
        "all_results = []\n",
        "for batch_index, batch in enumerate(chunk(reviews, BATCH_SIZE), start=1):\n",
        "    payload = [\n",
        "        {\n",
        "            \"review_id\": entry[\"review_id\"],\n",
        "            \"review_snippet\": entry.get(\"text\", \"\")\n",
        "        }\n",
        "        for entry in batch\n",
        "    ]\n",
        "    user_message = json.dumps(payload, ensure_ascii=False)\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_instruction},\n",
        "        {\"role\": \"user\",   \"content\": user_message}\n",
        "    ]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "    raw = response.choices[0].message.content.strip()\n",
        "\n",
        "    # === Option 1: Extract & clean JSON ===\n",
        "    m = re.search(r\"\\[.*\\]\", raw, re.DOTALL)\n",
        "    if not m:\n",
        "        print(f\"Batch {batch_index}: no JSON array found\\n{raw}\")\n",
        "        continue\n",
        "    arr_str = m.group(0)\n",
        "\n",
        "    # remove any trailing commas before } or ]\n",
        "    arr_str = re.sub(r\",\\s*([\\]\\}])\", r\"\\1\", arr_str)\n",
        "\n",
        "    try:\n",
        "        batch_results = json.loads(arr_str)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Batch {batch_index}: JSON parse failed after cleaning: {e}\")\n",
        "        continue\n",
        "\n",
        "    all_results.extend(batch_results)\n",
        "    print(f\"Processed batch {batch_index}, got {len(batch_results)} results.\")\n",
        "\n",
        "# Write to CSV, truncating snippet to first 50 chars\n",
        "csv_file = \"sentiment_results.csv\"\n",
        "with open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "    fieldnames = [\"review_id\", \"review_snippet\", \"sentiment\", \"score\"]\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "    for item in all_results:\n",
        "        writer.writerow({\n",
        "            \"review_id\":      item[\"review_id\"],\n",
        "            \"review_snippet\": item[\"review_snippet\"][:50],\n",
        "            \"sentiment\":      item[\"sentiment\"],\n",
        "            \"score\":          item[\"score\"]\n",
        "        })\n",
        "\n",
        "print(f\"Sentiment analysis complete. Total items: {len(all_results)}. Results saved to {csv_file}.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "azureml_py310_sdkv2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
