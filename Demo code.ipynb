{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NO9AQlONvNWs",
        "outputId": "2201da93-347f-4a5b-f6cf-e7123cc610df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.76.2)\n",
            "Collecting openai\n",
            "  Downloading openai-1.77.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Downloading openai-1.77.0-py3-none-any.whl (662 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.0/662.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.76.2\n",
            "    Uninstalling openai-1.76.2:\n",
            "      Successfully uninstalled openai-1.76.2\n",
            "Successfully installed openai-1.77.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rnsFHba_vSnf"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zc--KuHRvieu"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = '....'  # Enter OpenAI secret key\n",
        "\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq3ZhwTMPmyO",
        "outputId": "8f7ada0d-d398-4313-916e-d8f1a40073a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1, got 10 results.\n",
            "Processed batch 2, got 10 results.\n",
            "Processed batch 3, got 10 results.\n",
            "Processed batch 4, got 10 results.\n",
            "Processed batch 5, got 10 results.\n",
            "Processed batch 6, got 10 results.\n",
            "Processed batch 7, got 10 results.\n",
            "Processed batch 8, got 10 results.\n",
            "Processed batch 9, got 10 results.\n",
            "Processed batch 10, got 10 results.\n",
            "Processed batch 11, got 10 results.\n",
            "Processed batch 12, got 10 results.\n",
            "Processed batch 13, got 10 results.\n",
            "Processed batch 14, got 10 results.\n",
            "Processed batch 15, got 10 results.\n",
            "Processed batch 16, got 10 results.\n",
            "Processed batch 17, got 10 results.\n",
            "Batch 18: No JSON array found in response. Raw response:\n",
            "[{\"review_id\": \"Q0FPQXpgmAVyAeStInrcuA\", \"review_snippet\": \"Awesome place.  Enormous selections of clubs/equip\", \"sentiment\": \"Positive\", \"score\": 9}, {\"review_id\": \"R6BSs5jmGIP1UlTFyYVWhw\", \"review_snippet\": \"Food: Wife had the grilled vegetable salad (pictur\", \"sent...\n",
            "Processed batch 19, got 10 results.\n",
            "Processed batch 20, got 10 results.\n",
            "Sentiment analysis complete. Total items: 190. Results saved to sentiment_results.csv.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import csv\n",
        "from openai import OpenAI\n",
        "\n",
        "# Load your API key from environment variable\n",
        "OPENAI_API_KEY = '...'  # Enter OpenAI secret key\n",
        "\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "# Batch settings\n",
        "BATCH_SIZE = 10\n",
        "\n",
        "# System prompt for batched sentiment analysis\n",
        "system_instruction = \"\"\"\n",
        "You are an expert sentiment analyst. You will be given a JSON array of review objects.\n",
        "Each object has:\n",
        "  - review_id: a unique identifier for the review\n",
        "  - review_snippet: the first 50 characters of the review text\n",
        "For each object, return a new object with keys:\n",
        "  - review_id: same identifier\n",
        "  - review_snippet: the original snippet\n",
        "  - sentiment: one of \\\"Positive\\\", \\\"Neutral\\\", or \\\"Negative\\\"\n",
        "  - score: an integer from 0 to 10 representing how positive it is\n",
        "Return only a JSON array of these objects, without any additional text.\n",
        "\"\"\"\n",
        "\n",
        "# Helper to split list into batches\n",
        "def chunk(lst, size):\n",
        "    for i in range(0, len(lst), size):\n",
        "        yield lst[i:i + size]\n",
        "\n",
        "# Load dataset\n",
        "with open(\"sample_200_review.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    reviews = json.load(f)\n",
        "\n",
        "all_results = []\n",
        "for batch_index, batch in enumerate(chunk(reviews, BATCH_SIZE), start=1):\n",
        "    # Build list of dicts with review_id and snippet\n",
        "    payload = [\n",
        "        {\"review_id\": entry.get(\"review_id\"),\n",
        "         \"review_snippet\": entry.get(\"text\", \"\")[:50]}\n",
        "        for entry in batch\n",
        "    ]\n",
        "    user_message = json.dumps(payload, ensure_ascii=False)\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_instruction},\n",
        "        {\"role\": \"user\",   \"content\": user_message}\n",
        "    ]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "    raw = response.choices[0].message.content.strip()\n",
        "    try:\n",
        "        batch_results = json.loads(raw)\n",
        "    except json.JSONDecodeError:\n",
        "        # Attempt to extract JSON array from the response\n",
        "        start = raw.find('[')\n",
        "        end = raw.rfind(']')\n",
        "        if start != -1 and end != -1:\n",
        "            json_str = raw[start:end+1]\n",
        "            try:\n",
        "                batch_results = json.loads(json_str)\n",
        "            except json.JSONDecodeError:\n",
        "                print(f\"Batch {batch_index}: Failed to parse JSON even after extraction. Raw response:\\n{raw}\")\n",
        "                continue\n",
        "        else:\n",
        "            print(f\"Batch {batch_index}: No JSON array found in response. Raw response:\\n{raw}\")\n",
        "            continue\n",
        "\n",
        "    all_results.extend(batch_results)\n",
        "    print(f\"Processed batch {batch_index}, got {len(batch_results)} results.\")\n",
        "\n",
        "# Write to CSV\n",
        "csv_file = \"sentiment_results.csv\"\n",
        "with open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "    fieldnames = [\"review_id\", \"review_snippet\", \"sentiment\", \"score\"]\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "    for item in all_results:\n",
        "        writer.writerow(item)\n",
        "\n",
        "print(f\"Sentiment analysis complete. Total items: {len(all_results)}. Results saved to {csv_file}.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
